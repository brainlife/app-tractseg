#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import nibabel as nib
import numpy as np
import argparse
from scipy.ndimage.morphology import binary_dilation
from nibabel import trackvis
from tractseg.libs.FiberUtils import FiberUtils
from tractseg.libs.ExpUtils import ExpUtils
from dipy.tracking.utils import move_streamlines
from os.path import join


def get_length_best_orig_peak(predicted_img, orig_img, x, y, z):
    predicted = predicted_img[x, y, z, :]       # 1 peak
    orig = [orig_img[x, y, z, 0:3], orig_img[x, y, z, 3:6], orig_img[x, y, z, 6:9]]     # 3 peaks

    angle1 = abs(np.dot(predicted, orig[0]) / (np.linalg.norm(predicted) * np.linalg.norm(orig[0]) + 1e-7))
    angle2 = abs(np.dot(predicted, orig[1]) / (np.linalg.norm(predicted) * np.linalg.norm(orig[1]) + 1e-7))
    angle3 = abs(np.dot(predicted, orig[2]) / (np.linalg.norm(predicted) * np.linalg.norm(orig[2]) + 1e-7))

    argmax = np.argmax([angle1, angle2, angle3])
    best_peak_len = np.linalg.norm(orig[argmax])
    return best_peak_len


def evaluate_along_streamlines(scalar_img, streamlines, beginnings, nr_points, dilate=0, predicted_peaks=None):
    values = []
    for i in range(nr_points):
        values.append([])

    for i in range(dilate):     #no dilation if dilate=0
        beginnings = binary_dilation(beginnings)

    ctr = 0
    for idx, sl in enumerate(streamlines):
        startpoint = sl[0]
        #Flip streamline if not in right order
        if beginnings[int(startpoint[0]), int(startpoint[1]), int(startpoint[2])] == 0:
            sl = sl[::-1,:]
            ctr += 1
        for jdx in range(sl.shape[0]):   #iterate over nr_points
            point = sl[jdx]
            if predicted_peaks is not None:
                scalar_value = get_length_best_orig_peak(predicted_peaks, scalar_img, int(point[0]), int(point[1]), int(point[2]))
            else:
                scalar_value = scalar_img[int(point[0]), int(point[1]), int(point[2])]
            values[jdx].append(scalar_value)

    values_mean = np.array(values).mean(axis=1)
    values_std = np.array(values).std(axis=1)
    return values_mean, values_std


parser = argparse.ArgumentParser(description="Evaluate image (e.g. FA) along fiber bundles.",
                                 epilog="Written by Jakob Wasserthal. Please reference 'Wasserthal et al. " +
                                        "TractSeg - Fast and accurate white matter tract segmentation. https://doi.org/10.1016/j.neuroimage.2018.07.070)'")
parser.add_argument("-i", metavar="tracking_dir", dest="tracking_dir", help="Folder containing the TractSeg tractograms (normally '.../tractseg_output/TOM_tracking')", required=True)
parser.add_argument("-o", metavar="csv_output", dest="csv_file_out", help="CSV output file containing the results", required=True)
parser.add_argument("-e", metavar="endings_dir", dest="endings_dir", help="Folder containing the TractSeg bundle endings segmentations " +
                                                                          "(normally '.../tractseg_output/endings_segmentations'). " +
                                                                          "Needed to ensure that all fibers are starting from the same side.", required=True)
parser.add_argument("-s", metavar="scalar_img", dest="scalar_img", help="Scalar image (e.g. FA) or peak image (MRtrix peaks) if using '--peak_length'", required=True)
parser.add_argument("--nr_points", metavar="n", dest="nr_points", help="Number of points along streamline to evaluate (default: 20)", default="20")
parser.add_argument("--peak_length", action="store_true",
                    help="Instead of taking values of scalar image along streamlines (e.g. FA) take the length of the " +
                         "peak pointing in the same direction as the respective bundle. Gives better results in areas of crossing fibers than FA.",
                    default=False)
parser.add_argument("--TOM", metavar="TOM_dir", dest="TOM_dir", help="Folder containing Tract Orientation Maps (TOMs) (normally '.../tractseg_output/TOM'). Needed if using the '--peak_length' option.")
parser.add_argument("--tracking_format", metavar="tck|trk", choices=["tck", "trk"], help="Set output format of tracking (default: trk)", default="trk")
args = parser.parse_args()

bundles = ExpUtils.get_bundle_names("All")[1:]
NR_POINTS = int(args.nr_points)
DILATION = 5
scalar_image = nib.load(args.scalar_img)

results = []
for bundle in bundles:
    if args.peak_length:
        predicted_peaks = nib.load(join(args.TOM_dir, bundle + ".nii.gz")).get_data()
    else:
        predicted_peaks = None
    beginnings = nib.load(join(args.endings_dir, bundle + "_b.nii.gz"))

    if args.tracking_format == "trk":
	streams, hdr = trackvis.read(join(args.tracking_dir, bundle + ".trk"))
        streamlines = [s[0] for s in streams]
    else:
        tck = nib.streamlines.load(join(args.tracking_dir, bundle + ".tck"))
	streamlines = tck.streamlines

    if len(streamlines) > 0:
        streamlines = FiberUtils.resample_fibers(streamlines, nb_points=NR_POINTS)    #mean over bundles
        streamlines = list(move_streamlines(streamlines, np.linalg.inv(scalar_image.get_affine())))
        mean, std = evaluate_along_streamlines(np.nan_to_num(scalar_image.get_data()), streamlines, beginnings.get_data(),
                                               NR_POINTS, dilate=DILATION, predicted_peaks=predicted_peaks)
    else:
        mean = np.zeros(NR_POINTS)
        std = np.zeros(NR_POINTS)
    results.append(mean)

bundle_string = ""
for bundle in bundles:
    bundle_string += bundle + ";"
bundle_string = bundle_string[:-1]

np.savetxt(args.csv_file_out, np.array(results).transpose(), delimiter=";", header=bundle_string, comments="")

